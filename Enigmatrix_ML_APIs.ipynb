{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShailenderGoyal/Team_2_-Salesforce_Hackathon/blob/main/Enigmatrix_ML_APIs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Po2gUTTKqex4"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install Dependencies\n",
        "!pip install xgboost lightgbm shap fastapi uvicorn pyngrok scikit-learn pandas numpy joblib nest_asyncio -q\n",
        "!pip install fastapi uvicorn nest_asyncio pyngrok langchain sentence-transformers google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDd_Buto4bHk"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import shap\n",
        "import joblib\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from pyngrok import ngrok\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRpH27yY4eRw"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Generate Synthetic Data\n",
        "features = {\n",
        "    'cdr_call_frequency': 0.35,\n",
        "    'cdr_call_duration': 0.30,\n",
        "    'num_contacts': 0.25,\n",
        "    'upi_transaction_frequency': 0.40,\n",
        "    'avg_mobile_wallet_balance': 0.38,\n",
        "    'bill_payment_timeliness': 0.45,\n",
        "    'residential_stability': 0.30,\n",
        "    'health_insurance': 0.28,\n",
        "    'app_usage_hours_per_week': 0.20,\n",
        "    'number_of_livestock': 0.16,\n",
        "    'shg_repayment_consistency': 0.42,\n",
        "    'age_years': 0.10,\n",
        "    'num_dependents': -0.10,\n",
        "    'subsidy_inflow_regularity': 0.35,\n",
        "    'land_holdings_acres': 0.38,\n",
        "    'num_two_wheelers': 0.25,\n",
        "    'num_four_wheelers': 0.32,\n",
        "    'gold_holding_value': 0.28,\n",
        "    'num_formal_loans': 0.30,\n",
        "    'num_informal_loans': -0.35,\n",
        "    'marital_status': 0.05\n",
        "}\n",
        "\n",
        "def generate_updated_synthetic_data(n=10000, seed=42):\n",
        "    np.random.seed(seed)\n",
        "    feature_names = list(features.keys())\n",
        "    correlations = np.array([features[f] for f in feature_names])\n",
        "    corr_matrix = np.outer(correlations, correlations)\n",
        "    np.fill_diagonal(corr_matrix, 1.0)\n",
        "    mean = np.zeros(len(feature_names))\n",
        "    raw_data = np.random.multivariate_normal(mean, corr_matrix, size=n)\n",
        "    df = pd.DataFrame(raw_data, columns=feature_names)\n",
        "\n",
        "    df['cdr_call_frequency'] = np.clip(np.exp(df['cdr_call_frequency']) * 5, 5, 150).round()\n",
        "    df['cdr_call_duration'] = np.clip(np.exp(df['cdr_call_duration']) * 2, 5, 600)\n",
        "    df['num_contacts'] = np.clip(np.exp(df['num_contacts']) * 2, 10, 250).round()\n",
        "    df['upi_transaction_frequency'] = np.clip(np.exp(df['upi_transaction_frequency']) * 2, 5, 250).round()\n",
        "    df['avg_mobile_wallet_balance'] = np.clip(1500 + 500 * df['avg_mobile_wallet_balance'], 0, None)\n",
        "    df['bill_payment_timeliness'] = (df['bill_payment_timeliness'] - df['bill_payment_timeliness'].min()) / (df['bill_payment_timeliness'].max() - df['bill_payment_timeliness'].min())\n",
        "    df['residential_stability'] = np.clip(5 + 2 * df['residential_stability'], 0, None)\n",
        "    df['health_insurance'] = np.clip(1 + df['health_insurance'], 0, 1)\n",
        "    df['app_usage_hours_per_week'] = np.clip(np.exp(df['app_usage_hours_per_week']), 0, 80)\n",
        "    df['number_of_livestock'] = np.clip(np.exp(df['number_of_livestock']), 0, 50).round()\n",
        "    df['shg_repayment_consistency'] = (df['shg_repayment_consistency'] - df['shg_repayment_consistency'].min()) / (df['shg_repayment_consistency'].max() - df['shg_repayment_consistency'].min())\n",
        "    df['age_years'] = np.clip(40 + 10 * df['age_years'], 18, 90).round()\n",
        "    df['num_dependents'] = np.clip(df['num_dependents'] + 2, 0, 10).round()\n",
        "    df['subsidy_inflow_regularity'] = (df['subsidy_inflow_regularity'] - df['subsidy_inflow_regularity'].min()) / (df['subsidy_inflow_regularity'].max() - df['subsidy_inflow_regularity'].min())\n",
        "    df['land_holdings_acres'] = np.clip(np.exp(df['land_holdings_acres']), 0, 20)\n",
        "    df['num_two_wheelers'] = np.clip(df['num_two_wheelers'] + 1, 0, 3).round()\n",
        "    df['num_four_wheelers'] = np.clip(df['num_four_wheelers'], 0, 2).round()\n",
        "    df['gold_holding_value'] = np.clip(10 + 5 * df['gold_holding_value'], 0, None)\n",
        "    df['num_formal_loans'] = np.clip(df['num_formal_loans'] + 1, 0, 10).round()\n",
        "    df['num_informal_loans'] = np.clip(df['num_informal_loans'] + 1, 0, 5).round()\n",
        "    df['marital_status'] = np.random.choice([0, 1], size=n, p=[0.4, 0.6])\n",
        "\n",
        "    return df\n",
        "\n",
        "df = generate_updated_synthetic_data()\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(df[list(features.keys())])\n",
        "weights = np.array(list(features.values()))\n",
        "weighted_sum = np.dot(scaled, weights)\n",
        "df['credit_score'] = (1 + 99 * (weighted_sum - weighted_sum.min()) / (weighted_sum.max() - weighted_sum.min()))\n",
        "df['credit_score'] = df['credit_score'].round().astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE_Enj4-4jKS"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Train-Test Split\n",
        "X = df.drop(columns=['credit_score'])\n",
        "y = df['credit_score']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dXlqlpb4qp2"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Train Ensemble Model\n",
        "xgb_model = xgb.XGBRegressor(tree_method='gpu_hist', gpu_id=0)\n",
        "lgb_model = lgb.LGBMRegressor(device='gpu')\n",
        "xgb_model.fit(X_train, y_train)\n",
        "lgb_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZmiqwUt4s4r"
      },
      "outputs": [],
      "source": [
        "# Cell 6: SHAP Explanation\n",
        "explainer = shap.Explainer(xgb_model)\n",
        "shap_values = explainer(X_test[:100])\n",
        "mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
        "scaler_shap = MinMaxScaler(feature_range=(1, 100))\n",
        "importance_scaled = scaler_shap.fit_transform(mean_abs_shap.reshape(-1, 1)).flatten()\n",
        "feature_importance_dict = dict(zip(X.columns, importance_scaled.round(2)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-FJ-MbK4vsi"
      },
      "outputs": [],
      "source": [
        "# Cell 7: Save Models\n",
        "joblib.dump(xgb_model, \"xgb_model.pkl\")\n",
        "joblib.dump(lgb_model, \"lgb_model.pkl\")\n",
        "joblib.dump(feature_importance_dict, \"feature_importance.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l4yTA8pESDO"
      },
      "outputs": [],
      "source": [
        "pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SIYeU9J_NPj"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores.faiss import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document as LangchainDocument\n",
        "\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import importlib\n",
        "import datetime\n",
        "\n",
        "# add you gemini api key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"your_key_here\"\n",
        "class RAGGeminiSystem:\n",
        "    def __init__(self):\n",
        "        self.embedding_model = None\n",
        "        self.vector_store = None\n",
        "\n",
        "        self.embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=500,\n",
        "            chunk_overlap=50,\n",
        "            length_function=len\n",
        "        )\n",
        "\n",
        "        self._setup_gemini_api()\n",
        "        print(\"RAG-Gemini system initialized.\")\n",
        "\n",
        "    def _setup_gemini_api(self):\n",
        "        try:\n",
        "            api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "            if not api_key:\n",
        "                raise ValueError(\"Missing GOOGLE_API_KEY environment variable.\")\n",
        "            genai.configure(api_key=api_key)\n",
        "\n",
        "            self.gemini_model = genai.GenerativeModel(\"models/gemini-2.0-flash-lite\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Gemini API initialization failed: {str(e)}\")\n",
        "\n",
        "    def _load_embedding_model(self):\n",
        "        if self.embedding_model is None:\n",
        "            print(\"ðŸ”„ Loading embedding model...\")\n",
        "            try:\n",
        "                importlib.invalidate_caches()\n",
        "                self.embedding_model = HuggingFaceEmbeddings(\n",
        "                    model_name=self.embedding_model_name\n",
        "                )\n",
        "                print(\"Embedding model loaded.\")\n",
        "            except ImportError:\n",
        "                raise RuntimeError(\n",
        "                    \"sentence-transformers is not installed. Run: pip install sentence-transformers\"\n",
        "                )\n",
        "\n",
        "    def add_documents(self, documents):\n",
        "        try:\n",
        "            self._load_embedding_model()\n",
        "\n",
        "            all_chunks = []\n",
        "            for doc in documents:\n",
        "                chunks = self.text_splitter.split_text(doc[\"content\"])\n",
        "                for chunk in chunks:\n",
        "                    all_chunks.append(\n",
        "                        LangchainDocument(page_content=chunk, metadata=doc[\"metadata\"])\n",
        "                    )\n",
        "\n",
        "            if not all_chunks:\n",
        "                return {\"status\": \"error\", \"message\": \"No valid document content to index.\"}\n",
        "\n",
        "            if self.vector_store is None:\n",
        "                self.vector_store = FAISS.from_documents(all_chunks, self.embedding_model)\n",
        "            else:\n",
        "                self.vector_store.add_documents(all_chunks)\n",
        "\n",
        "            return {\n",
        "                \"status\": \"success\",\n",
        "                \"message\": f\"Added {len(documents)} documents with {len(all_chunks)} total chunks.\"\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"status\": \"error\", \"message\": f\"Failed to add documents: {str(e)}\"}\n",
        "\n",
        "    def answer_question(self, question, top_k=3, store_response=True):\n",
        "        try:\n",
        "            if self.vector_store is None:\n",
        "                return {\"status\": \"error\", \"message\": \"Knowledge base is empty.\"}\n",
        "\n",
        "            self._load_embedding_model()\n",
        "\n",
        "            docs = self.vector_store.similarity_search(question, k=top_k)\n",
        "            contexts = [doc.page_content for doc in docs]\n",
        "            combined_context = \"\\n\\n\".join(contexts)\n",
        "\n",
        "            prompt = (\n",
        "                f\"You are a helpful assistant with access to the following context:\\n\\n\"\n",
        "                f\"{combined_context}\\n\\n\"\n",
        "                f\"Based on the above information, answer the following question and respond cleanly without any markup symbols:\\n\"\n",
        "                f\"{question}\"\n",
        "            )\n",
        "\n",
        "            # Use Gemini to generate response\n",
        "            response = self.gemini_model.generate_content(prompt)\n",
        "\n",
        "            if not hasattr(response, \"text\") or not response.text.strip():\n",
        "                answer = \"I don't have enough information to answer that question.\"\n",
        "            else:\n",
        "                answer = response.text.strip()\n",
        "\n",
        "            # Optionally add Gemini's answer to vector DB\n",
        "            if store_response and answer:\n",
        "                metadata = {\n",
        "                    \"source\": \"gemini_response\",\n",
        "                    \"question\": question,\n",
        "                    \"timestamp\": datetime.datetime.now().isoformat()\n",
        "                }\n",
        "                doc = {\"content\": answer, \"metadata\": metadata}\n",
        "                self.add_documents([doc])\n",
        "\n",
        "            return {\n",
        "                \"status\": \"success\",\n",
        "                \"answer\": answer,\n",
        "                \"sources\": [{\"content\": doc.page_content, \"metadata\": doc.metadata} for doc in docs]\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"status\": \"error\", \"message\": f\"Failed to answer question: {str(e)}\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_lX-H8V40fU"
      },
      "outputs": [],
      "source": [
        "# Cell 8: Define FastAPI Inference App with Credit Scoring + RAG-Gemini Support\n",
        "!pip install fastapi uvicorn nest_asyncio pyngrok shap sentence-transformers langchain google-generativeai\n",
        "\n",
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# === Credit Model Setup ===\n",
        "explainer = shap.Explainer(xgb_model)\n",
        "\n",
        "# Initialize FastAPI and CORS\n",
        "app = FastAPI()\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"], allow_credentials=True, allow_methods=[\"*\"], allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# === Credit Prediction Schema ===\n",
        "class InputFeatures(BaseModel):\n",
        "    cdr_call_frequency: float\n",
        "    cdr_call_duration: float\n",
        "    num_contacts: float\n",
        "    upi_transaction_frequency: float\n",
        "    avg_mobile_wallet_balance: float\n",
        "    bill_payment_timeliness: float\n",
        "    residential_stability: float\n",
        "    health_insurance: float\n",
        "    app_usage_hours_per_week: float\n",
        "    number_of_livestock: float\n",
        "    shg_repayment_consistency: float\n",
        "    age_years: float\n",
        "    num_dependents: float\n",
        "    subsidy_inflow_regularity: float\n",
        "    land_holdings_acres: float\n",
        "    num_two_wheelers: float\n",
        "    num_four_wheelers: float\n",
        "    gold_holding_value: float\n",
        "    num_formal_loans: float\n",
        "    num_informal_loans: float\n",
        "    marital_status: int\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "def predict_credit_score(features: InputFeatures):\n",
        "    input_dict = features.dict()\n",
        "    input_df = pd.DataFrame([input_dict])\n",
        "\n",
        "    # Predict using ensemble\n",
        "    xgb_pred = xgb_model.predict(input_df)[0]\n",
        "    lgbm_pred = lgb_model.predict(input_df)[0]\n",
        "    final_pred = (0.5 * xgb_pred) + (0.5 * lgbm_pred)\n",
        "\n",
        "    # SHAP explanation\n",
        "    shap_values = explainer(input_df)\n",
        "    abs_vals = np.abs(shap_values.values[0])\n",
        "    max_val = abs_vals.max() if abs_vals.max() != 0 else 1.0\n",
        "\n",
        "    normalized_scores = {\n",
        "        feature: int(1 + 99 * (val / max_val))\n",
        "        for feature, val in zip(input_df.columns, abs_vals)\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"prediction\": float(final_pred),\n",
        "        \"shap_scores\": normalized_scores\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate shared RAG system\n",
        "rag_system = RAGGeminiSystem()\n",
        "\n",
        "class DocumentItem(BaseModel):\n",
        "    content: str\n",
        "    metadata: dict = {}\n",
        "\n",
        "class AddDocumentsRequest(BaseModel):\n",
        "    documents: list[DocumentItem]\n",
        "\n",
        "class AskQuestionRequest(BaseModel):\n",
        "    question: str\n",
        "    top_k: int = 3\n",
        "    store_response: bool = True\n",
        "\n",
        "@app.post(\"/rag/add_documents\")\n",
        "async def add_documents(request: AddDocumentsRequest):\n",
        "    docs = [{\"content\": d.content, \"metadata\": d.metadata} for d in request.documents]\n",
        "    return rag_system.add_documents(docs)\n",
        "\n",
        "@app.post(\"/rag/ask_question\")\n",
        "async def ask_question(request: AskQuestionRequest):\n",
        "    return rag_system.answer_question(\n",
        "        question=request.question,\n",
        "        top_k=request.top_k,\n",
        "        store_response=request.store_response\n",
        "    )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hsb9d56ZqkZ1"
      },
      "outputs": [],
      "source": [
        "#deployment\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "import os\n",
        "from pyngrok import ngrok\n",
        "\n",
        "\n",
         "NGROK_AUTH_TOKEN = \"your_actual_token_here\" # Replace this with your own token\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "# Create a public URL\n",
        "public_url = ngrok.connect(8056)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# Apply nest_asyncio to allow nested event loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Start the FastAPI server\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8056)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25mwqUwDsGwU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
